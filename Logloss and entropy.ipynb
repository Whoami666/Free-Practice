{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Пользуясь только python и Numpy посчитайте значения logloss и кросс-энтропии для мультилейбл и мультиклассовой классификации. Суммируйте значения функции ошибки для разных объектов.\n","\n","На вход программе подаются nn и kk – количество ответов и классов. Следующие 2n2n задают yy и значения последнего слоя до активации ZZ."],"metadata":{"id":"MBtX2ibtLpKb"}},{"cell_type":"markdown","source":["Sample Input 1:\n","\n","2 2\n","\n","1 0\n","\n","0 1\n","\n","-3.0 2.0\n","\n","0.0 1.0\n","\n","Sample Output 1:\n","\n","6.182 5.32"],"metadata":{"id":"YB1gut6rn19N"}},{"cell_type":"code","source":["import numpy as np        \n","\n","def sigmoid(x):\n","    return 1/(1 + np.exp(-x))\n","\n","def softmax1(z):\n","    e_x = np.exp(z - np.max(z))\n","    return e_x / e_x.sum(axis=0)\n","\n","def softmax(x):\n","    return(np.exp(x)/np.sum(np.exp(x), axis=1, keepdims=True))\n","\n","def logloss(y, y_hat):\n","    y_hat = sigmoid(y_hat)\n","    loss = -np.sum(y*(np.log(y_hat)) + (1-y)*np.log(1-y_hat))\n","    return loss\n","\n","def cross_entropy_loss(y, y_hat):\n"," #   y_hat = softmax(y_hat)\n","    return -np.sum(y*np.log(y_hat))\n","\n","def solution():\n","    n, k = map(int, input().split())\n","    y = np.array([list(map(int, input().split())) for _ in range(n)])\n","    z = np.array([list(map(float, input().split())) for _ in range(n)])\n","\n","    logloss_value = logloss(y, z)\n","    crossentropy_value = cross_entropy_loss(y, softmax(z))\n","\n","    logloss_value = str(np.round(logloss_value, 3))\n","    crossentropy_value = str(np.round(crossentropy_value, 3))\n","    print(logloss_value + ' ' + crossentropy_value)\n","\n","solution()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqddjLwEe1Vq","executionInfo":{"status":"ok","timestamp":1668940774237,"user_tz":-180,"elapsed":20423,"user":{"displayName":"Business True","userId":"15990550246125825368"}},"outputId":"9d69d03c-01f3-4e6e-c070-8c58829c2ca4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2 2\n","1 0\n","0 1\n","-3 2\n","0 1\n","6.182 5.32\n"]}]},{"cell_type":"markdown","source":["**Всякие тестики на эту тему**"],"metadata":{"id":"r1XJ5wv2MKKU"}},{"cell_type":"code","source":["import torch\n","import numpy as np"],"metadata":{"id":"LF6VK8cpNn8v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sig(x):\n"," return 1/(1 + np.exp(-x))"],"metadata":{"id":"_O22FL_NNpDJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x1 = [0.333, 0.5, 5.0]\n","x2 = [0.666, 0.25, 10]\n","x3 = [0.999, 0.1, 1]\n","x4 = [0.1, 0.1, 0.2]\n","w1 = np.array([[-0.5, -0.5], [0., 1.], [1.5, 3.0]])\n","w2 = np.array([[2.5, 0.5, -1.5], [3.5, 1.5, 1.5]])\n","b1 = [0., 0.]\n","b2 = [0., 0., 0.]\n","#a = sigmoida(z1)\n","y=[1,2,0,1]"],"metadata":{"id":"WZ2keq5GMJ02"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = np.array([x1, x2, x3, x4])\n","\n","xw1 = x@w1\n","print(xw1)\n","print(\"sigmoid(xw1) =\", sig(xw1))\n","print(x@w1@w2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0BTd_NtNzwS","executionInfo":{"status":"ok","timestamp":1667838289342,"user_tz":-180,"elapsed":286,"user":{"displayName":"Business True","userId":"15990550246125825368"}},"outputId":"b235508c-8741-4bb1-b968-833e9ddd3140"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 7.3335 15.3335]\n"," [14.667  29.917 ]\n"," [ 1.0005  2.6005]\n"," [ 0.25    0.65  ]]\n","sigmoid(xw1) = [[0.99934714 0.99999978]\n"," [0.99999957 1.        ]\n"," [0.73115687 0.93089375]\n"," [0.5621765  0.65701046]]\n","[[ 72.001  26.667  12.   ]\n"," [141.377  52.209  22.875]\n"," [ 11.603   4.401   2.4  ]\n"," [  2.9     1.1     0.6  ]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"F-FiBXdD6DL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","loss = torch.nn.CrossEntropyLoss(reduction='mean')\n","\n","\n",">>> output = loss(input, target)\n",">>> output.backward()"],"metadata":{"id":"ffJ8tmzgNHDc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"T_RWlFpg7w0e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8GwRoqUi7wxD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = np.array([1, 0, 3])@np.array([[1], [2], [3]]) - 10\n","print(a)\n","sig(a)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7bhN4tFA7wsU","executionInfo":{"status":"ok","timestamp":1667838927703,"user_tz":-180,"elapsed":14,"user":{"displayName":"Business True","userId":"15990550246125825368"}},"outputId":"d535f207-31a1-4c67-97e8-b863bff631fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0]\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0.5])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["X = torch.tensor([[0.333, 0.5, 5.0], [0.666, 0.25, 10.0],\n","                  [0.999, 0.1, 1.0], [0.1, 0.1, 0.2]], requires_grad=False)\n","W1 = torch.tensor([[-1.5, 0, 1.5],[-0.5, 1., 3.0]], requires_grad=True)\n","b1 = torch.tensor([[0.,0.]], requires_grad=True)\n","W2 = torch.tensor([[2.5, 3.5],[0.5, 1.5], [-1.5, 1.5]], requires_grad=True)\n","b2 = torch.tensor([[0., 0., 0.]], requires_grad=True)\n","y = torch.tensor([1 ,2, 0,1 ])\n","\n","a1 = torch.sigmoid(X @ W1.T + b1) \n","z2 = (a1 @ W2.T + b2)\n","CrossEntropyLossCrossEntropyLoss = torch.nn.CrossEntropyLoss( reduction='mean')\n","loss = CrossEntropyLossCrossEntropyLoss(z2, y)\n","loss.backward()\n","print(\"loss\", loss)\n","print(b1.grad)\n","print(\"suM\", loss + b1.grad[0])"],"metadata":{"id":"IgAihSwW75fH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667986958422,"user_tz":-180,"elapsed":6,"user":{"displayName":"Business True","userId":"15990550246125825368"}},"outputId":"2a18af23-410d-4c57-84f4-8ab68b9646b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loss tensor(3.1549, grad_fn=<NllLossBackward0>)\n","tensor([[0.0962, 0.0980]])\n","suM tensor([3.2510, 3.2529], grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HjjxoDdwwhsw"},"execution_count":null,"outputs":[]}]}